{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Multiple Linear Regression","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7"},"kernelspec":{"name":"python3","display_name":"Python 3.8.3 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"b3c5e2cbc54746db6a988fb5ed3e4ca3da723da73a132923ac78a43da41fb1f0"}},"cells":[{"cell_type":"markdown","source":["# Multiple Linear Regression\r\n","The business challenge: we have 50 companies in total and the have extracts from their income statements (R$D, Admin, Marketing, State, Profit)\r\n","\r\n","Create a model that will output the profit based on the factors and allow a venture capitalist firm to identify the type of companies they should look for. e.g. spending more or less on R&D compared to marketing New York over Florida. We want to maximize the VC profit."],"metadata":{"id":"CazISR8X_HUG","colab_type":"text"}},{"cell_type":"markdown","source":["Multiple Regression Intuition: when we want multiple explanatory variables to account for the response variable\r\n","\r\n","y = b + m1x1 + m2x2 + m3x3"],"metadata":{}},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"pOyqYHTk_Q57","colab_type":"text"}},{"cell_type":"code","execution_count":3,"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd"],"outputs":[],"metadata":{"id":"T_YHJjnD_Tja","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Importing the dataset"],"metadata":{"id":"vgC61-ah_WIz","colab_type":"text"}},{"cell_type":"code","execution_count":25,"source":["dataset = pd.read_csv('50_Startups.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, -1].values\r\n"],"outputs":[],"metadata":{"id":"UrxyEKGn_ez7","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Checking for correlations"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["dataset.corr()['Profit'].sort_values(ascending = False)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["Profit             1.000000\n","R&D Spend          0.972900\n","Marketing Spend    0.747766\n","Administration     0.200717\n","Name: Profit, dtype: float64"]},"metadata":{},"execution_count":13}],"metadata":{"id":"GOB3QhV9B5kD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":857},"outputId":"4a05377a-2db2-43fc-b824-a0710448baee","executionInfo":{"status":"ok","timestamp":1586353652778,"user_tz":-240,"elapsed":552,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"}}}},{"cell_type":"markdown","source":["R$D Spending and Marketing Spending seem to be more correlated and useful, but nonetheless, we should still include it as a part of our values\r\n","\r\n","Ideally, we don't want to include ALL the variables. This is known as feature selection because we want to chose the most relevant predictors of the response variable. \r\n","\r\n","It is also ok if the model does not work properly because there are so many more models that we can use. We don't have to check for the assumptions because it is just a waste of time. We can chose a model as a hypothesis, not as a definite solution."],"metadata":{}},{"cell_type":"markdown","source":["## Encoding categorical data and Imputing Missing Data"],"metadata":{"id":"VadrvE7s_lS9","colab_type":"text"}},{"cell_type":"code","execution_count":26,"source":["#Used for the State\r\n","#Remember from the Part 1 the column transformer and one hot encoder\r\n","\r\n","from sklearn.impute import SimpleImputer\r\n","imr = SimpleImputer(missing_values=np.nan, strategy='mean')\r\n","imr = imr.fit(X[:,:3])\r\n","X[:,:3] = imr.transform(X[:,:3])\r\n","\r\n","from sklearn.compose import ColumnTransformer\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')  #3 because that is the fourth column (python indexing!!)\r\n","X = np.array(ct.fit_transform(X))\r\n","\r\n","\r\n"],"outputs":[],"metadata":{"id":"wV3fD1mbAvsh","colab_type":"code","colab":{}}},{"cell_type":"code","execution_count":27,"source":["print(X)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"metadata":{"id":"4ym3HdYeCGYG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":857},"outputId":"ce09e670-cf06-4a1c-f5b0-89422aae0496","executionInfo":{"status":"ok","timestamp":1586353657759,"user_tz":-240,"elapsed":616,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"}}}},{"cell_type":"markdown","source":["NOTE: We do not need to use feature scaling because the coefficients for each of the independent variables will be accordingly adjusted. It is only really used for when calculating the distance between two datapoints"],"metadata":{}},{"cell_type":"markdown","source":["## Splitting the dataset into the Training set and Test set"],"metadata":{"id":"WemVnqgeA70k","colab_type":"text"}},{"cell_type":"code","execution_count":28,"source":["from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"outputs":[],"metadata":{"id":"Kb_v_ae-A-20","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Training the Multiple Linear Regression model on the Training set"],"metadata":{"id":"k-McZVsQBINc","colab_type":"text"}},{"cell_type":"code","execution_count":31,"source":["from sklearn.linear_model import LinearRegression\r\n","regressor = LinearRegression()\r\n","regressor.fit(X_train, y_train)\r\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression()"]},"metadata":{},"execution_count":31}],"metadata":{"id":"ywPjx0L1BMiD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"099836bc-4d85-4b4f-a488-093faf02e8cb","executionInfo":{"status":"ok","timestamp":1586353664008,"user_tz":-240,"elapsed":757,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"}}}},{"cell_type":"markdown","source":["## Metrics, R^2 Value"],"metadata":{}},{"cell_type":"code","execution_count":33,"source":["regressor.score(X_test, y_test)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9347068473282303"]},"metadata":{},"execution_count":33}],"metadata":{}},{"cell_type":"markdown","source":["## Predicting the Test set results"],"metadata":{"id":"xNkXL1YQBiBT","colab_type":"text"}},{"cell_type":"code","execution_count":47,"source":["y_pred = regressor.predict(X_test)\r\n","#This code takes the predicted and test values and makes a dictionary of them, which is then converted into a pandas dataframe\r\n","values = [y_pred, y_test]\r\n","labels = [\"predicted\", \"actual\"]\r\n","data_compar = pd.DataFrame(dict(zip(labels, values)))\r\n"],"outputs":[],"metadata":{"id":"TQKmwvtdBkyb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"493436bf-a4ae-4374-ca16-0b0c25d19457","executionInfo":{"status":"ok","timestamp":1586353666678,"user_tz":-240,"elapsed":951,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"}}}},{"cell_type":"markdown","source":["## Calculating the differenece betweeen the predicted and actual values"],"metadata":{}},{"cell_type":"code","execution_count":48,"source":["#lambda is a really useful function worth learning. It applies the calculaute difference function to the entire data columns of the predicted and actual, and each row in a new column Difference will be \r\n","#the difference between the two rows\r\n","\r\n","import math\r\n","def calc_diff(pred,real):\r\n","    return pred-real\r\n","data_compar[\"Difference\"] = data_compar.apply(lambda x: calc_diff(x.predicted, x.actual), axis =1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":52,"source":["data_compar"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       predicted     actual    Difference\n","0  103015.201598  103282.38   -267.178402\n","1  132582.277608  144259.40 -11677.122392\n","2  132447.738452  146121.95 -13674.211548\n","3   71976.098513   77798.83  -5822.731487\n","4  178537.482211  191050.39 -12512.907789\n","5  116161.242302  105008.31  11152.932302\n","6   67851.692097   81229.06 -13377.367903\n","7   98791.733747   97483.56   1308.173747\n","8  113969.435330  110352.25   3617.185330\n","9  167921.065696  166187.94   1733.125696"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predicted</th>\n","      <th>actual</th>\n","      <th>Difference</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>103015.201598</td>\n","      <td>103282.38</td>\n","      <td>-267.178402</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>132582.277608</td>\n","      <td>144259.40</td>\n","      <td>-11677.122392</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>132447.738452</td>\n","      <td>146121.95</td>\n","      <td>-13674.211548</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>71976.098513</td>\n","      <td>77798.83</td>\n","      <td>-5822.731487</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>178537.482211</td>\n","      <td>191050.39</td>\n","      <td>-12512.907789</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>116161.242302</td>\n","      <td>105008.31</td>\n","      <td>11152.932302</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>67851.692097</td>\n","      <td>81229.06</td>\n","      <td>-13377.367903</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>98791.733747</td>\n","      <td>97483.56</td>\n","      <td>1308.173747</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>113969.435330</td>\n","      <td>110352.25</td>\n","      <td>3617.185330</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>167921.065696</td>\n","      <td>166187.94</td>\n","      <td>1733.125696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":52}],"metadata":{}},{"cell_type":"code","execution_count":53,"source":["data_compar[\"Difference\"].mean()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["-3952.0102448099483"]},"metadata":{},"execution_count":53}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}